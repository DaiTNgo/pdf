{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ee369e138efa914",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cdacb7ad5e3c4a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:23.438699300Z",
     "start_time": "2023-11-23T03:12:20.427316200Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index import set_global_service_context\n",
    "from llama_index.prompts import PromptTemplate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "911cbc95",
   "metadata": {},
   "source": [
    "# Read documents and Split into nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d68a9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:27.712129900Z",
     "start_time": "2023-11-23T03:12:23.438699300Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./pdf\").load_data()\n",
    "node_parser = SimpleNodeParser.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ca0ca99f8a757c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:27.726182300Z",
     "start_time": "2023-11-23T03:12:27.714071300Z"
    }
   },
   "outputs": [],
   "source": [
    "# nodes = node_parser.get_nodes_from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a5ecd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:27.749522400Z",
     "start_time": "2023-11-23T03:12:27.730490900Z"
    }
   },
   "outputs": [],
   "source": [
    "# nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f245b60ea73bf98",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d82afaf267b9c42d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:33.978569800Z",
     "start_time": "2023-11-23T03:12:27.748448900Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "\n",
    "# embed_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "# embed_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name = \"BAAI/bge-base-en-v1.5\", cache_folder = 's_bert',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56781f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:35.796521500Z",
     "start_time": "2023-11-23T03:12:33.982821800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/msmarco-distilbert-base-dot-prod-v3 and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "postprocessor = SentenceTransformerRerank(\n",
    "  model = \"sentence-transformers/msmarco-distilbert-base-dot-prod-v3\",\n",
    "  top_n = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3d4bb0b3941742",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:36.238852100Z",
     "start_time": "2023-11-23T03:12:35.801018300Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "llm = OpenAI(model='gpt-3.5-turbo', max_tokens=512, temperature=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35070e9622f7af0f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9beb949a9457158c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:36.971684500Z",
     "start_time": "2023-11-23T03:12:36.243692700Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./dbb\")\n",
    "# chroma_client.delete_collection(name=\"qa-pdf\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(name=\"qa-pdf\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cda8713093c891e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:36.990364800Z",
     "start_time": "2023-11-23T03:12:36.966817300Z"
    }
   },
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d615a1a12f52592",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a818c018dc44001e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:37.011917100Z",
     "start_time": "2023-11-23T03:12:36.990364800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a504c3b256fd3ec9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:37.022848900Z",
     "start_time": "2023-11-23T03:12:37.007333700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# \n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e4741236697a19",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:37.036480200Z",
     "start_time": "2023-11-23T03:12:37.022848900Z"
    }
   },
   "outputs": [],
   "source": [
    "# from llama_index.prompts import PromptTemplate\n",
    "\n",
    "# system_prompt = \"\"\"<|SYSTEM|># StableLM Tuned (Alpha version)\n",
    "# - StableLM is a helpful and harmless open-source AI language model developed by StabilityAI.\n",
    "# - StableLM is excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n",
    "# - StableLM is more than just an information source, StableLM is also able to write poetry, short stories.\n",
    "# - StableLM will refuse to participate in anything that could harm a human.\n",
    "# - StableLM Rewrite an answer that combines multiple data sources, semantically unchanged\n",
    "# \"\"\"\n",
    "\n",
    "# template = (\n",
    "#     \"We have provided context information below. \\n\"\n",
    "#     \"---------------------\\n\"\n",
    "#     \"{context_str}\"\n",
    "#     \"\\n---------------------\\n\"\n",
    "#     \"Given this information, please answer the question: {query_str}\\n\"\n",
    "# )\n",
    "# qa_template = PromptTemplate(template)\n",
    "# \n",
    "# system_prompt = \"\"\"\n",
    "# - StableLM Rewrite an answer that combines multiple data sources, semantically unchanged\n",
    "# \"\"\"\n",
    "# # This will wrap the default prompts that are internal to llama-index\n",
    "# query_wrapper_prompt = PromptTemplate(\"<|USER|>{query_str}<|ASSISTANT|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47514c70dab2002b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:37.063625100Z",
     "start_time": "2023-11-23T03:12:37.041981Z"
    }
   },
   "outputs": [],
   "source": [
    "# from llama_index.prompts import PromptTemplate\n",
    "# \n",
    "# text_qa_template_str = (\n",
    "#     \"Context information is\"\n",
    "#     \" below.\\n---------------------\\n{context_str}\\n---------------------\\nUsing\"\n",
    "#     \" both the context information and also using your own knowledge, answer\"\n",
    "#     \" the question: {query_str}\\nIf the context isn't helpful, you can also\"\n",
    "#     \" answer the question on your own.\\n\"\n",
    "# )\n",
    "# text_qa_template = PromptTemplate(text_qa_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee186f47c36d59d8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:38.874151400Z",
     "start_time": "2023-11-23T03:12:37.057731600Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model,\n",
    "    node_parser=node_parser,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6281ea8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:38.889035400Z",
     "start_time": "2023-11-23T03:12:38.877367900Z"
    }
   },
   "outputs": [],
   "source": [
    "set_global_service_context(service_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e99922d0",
   "metadata": {},
   "source": [
    "# SET PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b695eb31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:38.912700Z",
     "start_time": "2023-11-23T03:12:38.890453500Z"
    }
   },
   "outputs": [],
   "source": [
    "#Question answering template\n",
    "text_qa_template_str = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Using both the context information and also using your own knowledge, \"\n",
    "    \"answer the question: {query_str}\\n\"\n",
    "    \"If the context isn't helpful, you can also answer the question on your own. You can choose answer the question by Vietnamese or English\\n\"\n",
    ")\n",
    "text_qa_template = PromptTemplate(text_qa_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66332743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T03:12:38.918397500Z",
     "start_time": "2023-11-23T03:12:38.908008400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Refine template\n",
    "refine_template_str = (\n",
    "    \"The original question is as follows: {query_str}\\n\"\n",
    "    \"We have provided an existing answer: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing answer \"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Using both the new context and your own knowledge, update or repeat the existing answer.\\n\"\n",
    ")\n",
    "refine_template = PromptTemplate(refine_template_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7acb261b34fb77fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dab30e198fb3670a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:13:12.185486100Z",
     "start_time": "2023-11-23T03:12:38.918397500Z"
    }
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "        documents = documents,\n",
    "        vector_store = vector_store,\n",
    "        service_context = service_context,\n",
    "        text_qa_template = text_qa_template,\n",
    "        refine_template = refine_template,\n",
    "        postprocessor = postprocessor,\n",
    "        storage_context=storage_context\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a16645952517d0b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72308bf8954f719b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:13:12.197545700Z",
     "start_time": "2023-11-23T03:13:12.185486100Z"
    }
   },
   "outputs": [],
   "source": [
    "# index = VectorStoreIndex.from_vector_store(\n",
    "#     vector_store = vector_store,\n",
    "#     storage_context=storage_context,\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4c826b104556b88",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e385a2689aa5f275",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Query the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801415ca46e9488f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T03:13:12.343161900Z",
     "start_time": "2023-11-23T03:13:12.197545700Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(\n",
    "        chat_mode = \"condense_question\",\n",
    "        verbose = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a34960bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T03:13:15.101683800Z",
     "start_time": "2023-11-23T03:13:12.343161900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: Can you explain what machine learning is?\n"
     ]
    }
   ],
   "source": [
    "streaming_response = chat_engine.stream_chat(\"What is machine learning?\")                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "018ed0f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T03:13:51.719249100Z",
     "start_time": "2023-11-23T03:13:15.072966800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a discipline of artificial intelligence that enables machines to learn from data and past experiences. It allows computers to automatically identify patterns and make predictions without explicit programming. Machine learning algorithms learn directly from data, rather than relying on predetermined equations, and improve their performance with more available samples. It has become essential in various fields, such as computational finance, computer vision, computational biology, automotive, aerospace, manufacturing, and natural language processing. Machine learning works by training algorithms on a dataset to create a model, which is then used to make predictions on new input data. The accuracy of the predictions is checked, and the algorithm is either deployed or trained repeatedly until the desired accuracy is achieved. Machine learning is broadly categorized into four main types based on different methods and ways of learning."
     ]
    }
   ],
   "source": [
    "for token in streaming_response.response_gen:\n",
    "    print(token, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
